FROM gcr.io/spark-operator/spark-operator:v1beta2-1.3.0-3.1.1

# https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/issues/404

# Add support to S3a connector.
ARG SPARK_VERSION="3.1.1"
ARG AWS_JAVA_SDK_VERSION="1.11.534"
ARG HADOOP_VERSION="3.2.0"

RUN rm -rf $SPARK_HOME

# gcr.io/spark-operator/spark-py:v3.1.1-hadoop3
COPY --from=gcr.io/spark-operator/spark-py:v3.1.1-hadoop3 /opt/spark $SPARK_HOME

# Add support to S3a connector.
ADD https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/${SPARK_VERSION}/hadoop-aws-${SPARK_VERSION}.jar $SPARK_HOME/jars
RUN chmod 644 $SPARK_HOME/jars/hadoop-aws-${SPARK_VERSION}.jar
ADD https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk/${AWS_JAVA_SDK_VERSION}/aws-java-sdk-${AWS_JAVA_SDK_VERSION}.jar $SPARK_HOME/jars
RUN chmod 644 $SPARK_HOME/jars/aws-java-sdk-${AWS_JAVA_SDK_VERSION}.jar
ADD https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-core/${AWS_JAVA_SDK_VERSION}/aws-java-sdk-core-${AWS_JAVA_SDK_VERSION}.jar $SPARK_HOME/jars
RUN chmod 644 $SPARK_HOME/jars/aws-java-sdk-core-${AWS_JAVA_SDK_VERSION}.jar
ADD https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-dynamodb/${AWS_JAVA_SDK_VERSION}/aws-java-sdk-dynamodb-${AWS_JAVA_SDK_VERSION}.jar $SPARK_HOME/jars
RUN chmod 644 $SPARK_HOME/jars/aws-java-sdk-dynamodb-${AWS_JAVA_SDK_VERSION}.jar
ADD https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-kms/${AWS_JAVA_SDK_VERSION}/aws-java-sdk-kms-${AWS_JAVA_SDK_VERSION}.jar $SPARK_HOME/jars
RUN chmod 644 $SPARK_HOME/jars/aws-java-sdk-kms-${AWS_JAVA_SDK_VERSION}.jar
ADD https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/${AWS_JAVA_SDK_VERSION}/aws-java-sdk-s3-${AWS_JAVA_SDK_VERSION}.jar $SPARK_HOME/jars
RUN chmod 644 $SPARK_HOME/jars/aws-java-sdk-s3-${AWS_JAVA_SDK_VERSION}.jar
ADD https://repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.3/httpclient-4.5.3.jar $SPARK_HOME/jars
RUN chmod 644 $SPARK_HOME/jars/httpclient-4.5.3.jar
ADD https://repo1.maven.org/maven2/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar $SPARK_HOME/jars
RUN chmod 644 $SPARK_HOME/jars/joda-time-2.9.9.jar

# Kafka libraries
ADD https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/${SPARK_VERSION}/spark-sql-kafka-0-10_2.12-${SPARK_VERSION}.jar $SPARK_HOME/jars
ADD https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/${SPARK_VERSION}/spark-token-provider-kafka-0-10_2.12-${SPARK_VERSION}.jar $SPARK_HOME/jars
ADD https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.4.1/kafka-clients-2.4.1.jar $SPARK_HOME/jars
ADD https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.6.2/commons-pool2-2.6.2.jar $SPARK_HOME/jars
# Avro library
ADD https://repo1.maven.org/maven2/org/apache/spark/spark-avro_2.12/${SPARK_VERSION}/spark-avro_2.12-${SPARK_VERSION}.jar $SPARK_HOME/jars

# Delta libraries
ADD https://repo1.maven.org/maven2/io/delta/delta-core_2.12/1.0.1/delta-core_2.12-1.0.1.jar $SPARK_HOME/jars
ADD https://repo1.maven.org/maven2/io/delta/delta-contribs_2.12/1.0.1/delta-contribs_2.12-1.0.1.jar $SPARK_HOME/jars

# Setup for the Prometheus JMX exporter.
# Add the Prometheus JMX exporter Java agent jar for exposing metrics sent to the JmxSink to Prometheus.
ADD https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.11.0/jmx_prometheus_javaagent-0.11.0.jar /prometheus/
RUN chmod 644 /prometheus/jmx_prometheus_javaagent-0.11.0.jar


ENV HADOOP_HOME /opt/hadoop
ENV HADOOP_CONF_DIR $HADOOP_HOME/conf
RUN mkdir -p $HADOOP_HOME/conf
COPY conf/core-site.xml $HADOOP_HOME/conf/
COPY conf/spark-env.sh $HADOOP_HOME/conf/
COPY conf/spark-defaults.conf $SPARK_HOME/conf/